[{"path":[]},{"path":"/EXPLAINER.html","id":"what-is-this","dir":"","previous_headings":"","what":"What is this?","title":"CausalInvestData Explainer","text":"CausalInvestData R package provides high-quality, simulated datasets designed developing, testing, teaching causal inference methods context institutional investment management.","code":""},{"path":"/EXPLAINER.html","id":"why-use-this-package","dir":"","previous_headings":"","what":"Why use this package?","title":"CausalInvestData Explainer","text":"Institutional finance professionals, data scientists, researchers often struggle find relevant datasets training causal models. package solves offering curated, labeled datasets simulate: Fund performance treatment interventions Portfolio allocation strategies Client behavioral outcomes (e.g., churn, satisfaction) Macroeconomic time-series shocks","code":""},{"path":"/EXPLAINER.html","id":"who-is-this-for","dir":"","previous_headings":"","what":"Who is this for?","title":"CausalInvestData Explainer","text":"Financial data scientists Quant researchers Academics teaching causal inference Developers testing causal ML pipelines","code":""},{"path":"/EXPLAINER.html","id":"use-cases","dir":"","previous_headings":"","what":"Use Cases","title":"CausalInvestData Explainer","text":"Propensity score matching investment strategy evaluation Causal forest models treatment heterogeneity Impact advisory services client churn Macroeconomic sensitivity testing","code":""},{"path":"/EXPLAINER.html","id":"where-is-it-hosted","dir":"","previous_headings":"","what":"Where is it hosted?","title":"CausalInvestData Explainer","text":"GitHub: https://github.com/edzai/CausalInvestData (Soon) R-universe: https://edzai.r-universe.dev pkgdown: https://edzai.github.io/CausalInvestData","code":""},{"path":"/EXPLAINER.html","id":"author","dir":"","previous_headings":"","what":"Author","title":"CausalInvestData Explainer","text":"Edzai Conilias Zvobwo | edzai@acalytica.com","code":""},{"path":"/articles/bayesian-causal-forests.html","id":"bayesian-causal-forests-bcf","dir":"Articles","previous_headings":"","what":"🌲 Bayesian Causal Forests (BCF)","title":"Bayesian Causal Forests (BCF) for Heterogeneous Treatment Effects","text":"Bayesian Causal Forests (BCF) nonparametric Bayesian approach estimating individual-level heterogeneous treatment effects modeling outcome treatment assignment using tree-based ensembles.","code":""},{"path":"/articles/bayesian-causal-forests.html","id":"simulate-data-with-heterogeneous-effects","dir":"Articles","previous_headings":"","what":"1. 🧪 Simulate Data with Heterogeneous Effects","title":"Bayesian Causal Forests (BCF) for Heterogeneous Treatment Effects","text":"","code":"set.seed(123) n <- 500  X1 <- rnorm(n) X2 <- rnorm(n) X3 <- rbinom(n, 1, 0.5) tau <- 2 + X1 - 0.5 * X2  # treatment effect varies by covariates W <- rbinom(n, 1, prob = plogis(0.4 * X1 - 0.3 * X2 + 0.5 * X3)) Y <- tau * W + 1.5 * X1 + 0.8 * X2 + 1.0 * X3 + rnorm(n)  df <- data.frame(X1, X2, X3, W, Y)"},{"path":"/articles/bayesian-causal-forests.html","id":"visualize-true-heterogeneous-effect","dir":"Articles","previous_headings":"","what":"2. 📈 Visualize True Heterogeneous Effect","title":"Bayesian Causal Forests (BCF) for Heterogeneous Treatment Effects","text":"","code":"ggplot(data.frame(X1, tau), aes(x = X1, y = tau)) +   geom_point(alpha = 0.4) +   geom_smooth(se = FALSE) +   labs(title = \"True Heterogeneous Treatment Effect by X1\",        x = \"X1\", y = \"Treatment Effect (tau)\") +   theme_minimal()"},{"path":"/articles/bayesian-causal-forests.html","id":"fit-a-bcf-model","dir":"Articles","previous_headings":"","what":"3. 📦 Fit a BCF Model","title":"Bayesian Causal Forests (BCF) for Heterogeneous Treatment Effects","text":"using bcf package:","code":"X <- as.matrix(df[, c(\"X1\", \"X2\", \"X3\")]) bcf_fit <- bcf(y = df$Y, z = df$W, x_control = X, x_moderate = X) tau_hat <- colMeans(bcf_fit$tau)"},{"path":"/articles/bayesian-causal-forests.html","id":"compare-estimated-vs--true-effects","dir":"Articles","previous_headings":"","what":"4. 🧪 Compare Estimated vs. True Effects","title":"Bayesian Causal Forests (BCF) for Heterogeneous Treatment Effects","text":"","code":"ggplot(data.frame(True = tau, Estimated = tau_hat), aes(x = True, y = Estimated)) +   geom_point(alpha = 0.4) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +   labs(title = \"True vs. Estimated Treatment Effects\",        x = \"True Effect\", y = \"Estimated Effect\") +   theme_minimal()"},{"path":"/articles/bayesian-causal-forests.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Bayesian Causal Forests (BCF) for Heterogeneous Treatment Effects","text":"Bayesian Causal Forests: - Estimate heterogeneous effects without strong parametric assumptions - Use Bayesian Additive Regression Trees (BART) internally - Require installation bcf package","code":""},{"path":"/articles/bayesian-causal-forests.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Bayesian Causal Forests (BCF) for Heterogeneous Treatment Effects","text":"Hahn, Murray, Carvalho (2020). Bayesian regression tree models causal inference: BCF approach Green & Kern (2012). Modeling heterogeneous treatment effects BART","code":""},{"path":"/articles/causal-discovery.html","id":"causal-discovery-learning-structure-from-data","dir":"Articles","previous_headings":"","what":"🧭 Causal Discovery: Learning Structure from Data","title":"Causal Discovery with DAGitty and Simulated Data","text":"Causal discovery aims infer causal structure (.e. DAG) observational data. useful domain knowledge limited exploratory analysis needed.","code":""},{"path":"/articles/causal-discovery.html","id":"simulate-data-with-known-dag","dir":"Articles","previous_headings":"","what":"1. ✨ Simulate Data with Known DAG","title":"Causal Discovery with DAGitty and Simulated Data","text":"","code":"set.seed(123) n <- 1000  X <- rnorm(n) Z <- 0.6 * X + rnorm(n) Y <- 0.5 * Z + 0.3 * X + rnorm(n)  df <- data.frame(X, Z, Y) head(df) ##             X          Z          Y ## 1 -0.56047565 -1.3320841 -1.3457885 ## 2 -0.23017749 -1.1780615 -0.4211461 ## 3  1.55870831  0.9172447  0.3846457 ## 4  0.07050839 -0.0898701  1.1954451 ## 5  0.12928774 -2.4717701 -1.0229629 ## 6  1.71506499  2.0696124  0.9340574"},{"path":"/articles/causal-discovery.html","id":"define-the-true-dag","dir":"Articles","previous_headings":"","what":"2. 🧠 Define the True DAG","title":"Causal Discovery with DAGitty and Simulated Data","text":"","code":"true_dag <- dagitty(\"dag {   X -> Z -> Y   X -> Y }\")  ggdag(true_dag, layout = \"circle\") +   ggtitle(\"True DAG Used to Generate Data\")"},{"path":"/articles/causal-discovery.html","id":"use-localtests-to-test-dependencies","dir":"Articles","previous_headings":"","what":"3. 🔍 Use localTests() to Test Dependencies","title":"Causal Discovery with DAGitty and Simulated Data","text":"use dagitty::localTests() test conditional independence statements implied candidate DAG: row checks whether conditional independence assumption holds (p > 0.05 supports claim).","code":"test_result <- localTests(true_dag, data = df, type = \"cis\") test_result ## data frame with 0 columns and 0 rows"},{"path":"/articles/causal-discovery.html","id":"try-an-incorrect-dag","dir":"Articles","previous_headings":"","what":"4. 🧪 Try an Incorrect DAG","title":"Causal Discovery with DAGitty and Simulated Data","text":"Now test: Look failed assumptions (low p-values).","code":"wrong_dag <- dagitty(\"dag {   Z -> X   Z -> Y   X -> Y }\")  ggdag(wrong_dag, layout = \"circle\") +   ggtitle(\"Incorrect DAG Assumption\") localTests(wrong_dag, data = df, type = \"cis\") ## data frame with 0 columns and 0 rows"},{"path":"/articles/causal-discovery.html","id":"assumptions-for-causal-discovery","dir":"Articles","previous_headings":"","what":"🧠 Assumptions for Causal Discovery","title":"Causal Discovery with DAGitty and Simulated Data","text":"Causal Sufficiency: common causes measured Faithfulness: Statistical independence reflects causal structure Measurement Error","code":""},{"path":"/articles/causal-discovery.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Causal Discovery with DAGitty and Simulated Data","text":"Causal discovery lets us: - Explore structures little prior knowledge - Validate assumptions - Compare competing causal hypotheses dagitty provides simple entry point. algorithmic discovery, explore pcalg, bnlearn, cdcs.","code":""},{"path":"/articles/causal-discovery.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Causal Discovery with DAGitty and Simulated Data","text":"Textor et al. (2016). dagitty: Graphical Analysis Structural Causal Models Spirtes, Glymour, Scheines (2000). Causation, Prediction, Search","code":""},{"path":"/articles/causal-impact.html","id":"causal-time-series-impact-analysis","dir":"Articles","previous_headings":"","what":"📅 Causal Time-Series Impact Analysis","title":"Causal Time-Series Impact Analysis","text":"Causal impact analysis estimates intervention affects outcome time. financial settings, might reflect effect policy change, economic shock, strategy shift.","code":""},{"path":"/articles/causal-impact.html","id":"load-the-macro-shocks-dataset","dir":"Articles","previous_headings":"","what":"📦 Load the Macro Shocks Dataset","title":"Causal Time-Series Impact Analysis","text":"’ll simulate intervention (e.g. policy shock) occurring time point 80.","code":"data(\"macro_shocks\") head(macro_shocks) ##         date interest_rate gdp_growth market_index ## 1 2020-01-01    0.04858548 0.02098241   0.03418012 ## 2 2020-02-01    0.03740164 0.02505696   0.05356738 ## 3 2020-03-01    0.04924685 0.02460699   0.04155380 ## 4 2020-04-01    0.05109889 0.01260686   0.01707771 ## 5 2020-05-01    0.02392792 0.02387595   0.02444632 ## 6 2020-06-01    0.06718417 0.01306215  -0.04220713"},{"path":"/articles/causal-impact.html","id":"create-prepost-intervention-periods","dir":"Articles","previous_headings":"","what":"🧪 Create Pre/Post-Intervention Periods","title":"Causal Time-Series Impact Analysis","text":"","code":"macro_shocks <- macro_shocks %>%   mutate(time = row_number(),          intervention = ifelse(time >= 80, 1, 0))"},{"path":"/articles/causal-impact.html","id":"plot-the-time-series","dir":"Articles","previous_headings":"","what":"📈 Plot the Time Series","title":"Causal Time-Series Impact Analysis","text":"","code":"ggplot(macro_shocks, aes(x = date, y = market_index)) +   geom_line() +   geom_vline(xintercept = macro_shocks$date[80], linetype = \"dashed\", color = \"red\") +   labs(title = \"Market Index with Simulated Intervention at Month 80\",        x = \"Date\", y = \"Market Index\") +   theme_minimal()"},{"path":"/articles/causal-impact.html","id":"estimate-counterfactual-using-linear-regression","dir":"Articles","previous_headings":"","what":"⚙️ Estimate Counterfactual Using Linear Regression","title":"Causal Time-Series Impact Analysis","text":"","code":"pre_data <- macro_shocks %>% filter(intervention == 0) post_data <- macro_shocks %>% filter(intervention == 1)  model <- lm(market_index ~ interest_rate + gdp_growth, data = pre_data) post_data$predicted <- predict(model, newdata = post_data)  ggplot(post_data, aes(x = date)) +   geom_line(aes(y = market_index), color = \"blue\") +   geom_line(aes(y = predicted), color = \"orange\", linetype = \"dashed\") +   labs(title = \"Observed vs Counterfactual Post-Intervention\",        y = \"Market Index\", x = \"Date\") +   theme_minimal()"},{"path":"/articles/causal-impact.html","id":"optional-use-causalimpact-package","dir":"Articles","previous_headings":"","what":"🧾 Optional: Use CausalImpact Package","title":"Causal Time-Series Impact Analysis","text":"installed:","code":"# install.packages(\"CausalImpact\") # library(CausalImpact)  # ts_data <- ts(macro_shocks$market_index, frequency = 12) # ts_covariates <- macro_shocks %>% select(interest_rate, gdp_growth) # impact <- CausalImpact(cbind(ts_data, ts_covariates), 1, 79) # plot(impact) # summary(impact)"},{"path":"/articles/causal-impact.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"✅ Conclusion","title":"Causal Time-Series Impact Analysis","text":"Using even simple pre/post modeling, can estimate market index might looked like “shock” occurred. approach helps analysts measure causal effect real-world events time.","code":""},{"path":"/articles/causal-impact.html","id":"citation","dir":"Articles","previous_headings":"","what":"📖 Citation","title":"Causal Time-Series Impact Analysis","text":"","code":"citation(\"CausalInvestData\") ## To cite the CausalInvestData package in publications, use: ##  ##   Conilias Zvobwo E (2025). _CausalInvestData: Simulated Datasets for ##   Causal Inference in Investment Management_. R package version 0.1.0, ##   <https://github.com/edzai/CausalInvestData>. ##  ## A BibTeX entry for LaTeX users is ##  ##   @Manual{, ##     title = {CausalInvestData: Simulated Datasets for Causal Inference in Investment Management}, ##     author = {Edzai {Conilias Zvobwo}}, ##     year = {2025}, ##     note = {R package version 0.1.0}, ##     url = {https://github.com/edzai/CausalInvestData}, ##   }"},{"path":"/articles/causal-methods-overview.html","id":"what-is-causal-inference","dir":"Articles","previous_headings":"","what":"🧠 What is Causal Inference?","title":"Causal Inference Methods Overview","text":"Causal inference process estimating effect intervention treatment outcome. Unlike correlation, causal inference requires assumptions data generated. article, use fund_performance dataset illustrate common methods.","code":"data(\"fund_performance\") head(fund_performance) ##   fund_id market_return        alpha      beta treatment       return ## 1       1   0.003952435 -0.009915974 0.9217857         0 -0.007775751 ## 2       2   0.036982251 -0.010799101 1.1331275         1  0.032828934 ## 3       3   0.215870831  0.009640395 1.0374590         1  0.224115880 ## 4       4   0.067050839  0.007356497 1.1228787         1  0.080673608 ## 5       5   0.072928774 -0.040986855 0.9176203         0  0.051918971 ## 6       6   0.231506499  0.030811469 0.8564341         0  0.228707376"},{"path":"/articles/causal-methods-overview.html","id":"naive-difference-in-means","dir":"Articles","previous_headings":"","what":"⚖️ 1. Naive Difference in Means","title":"Causal Inference Methods Overview","text":"method assumes random treatment assignment.","code":"fund_performance %>%   group_by(treatment) %>%   summarise(mean_return = mean(return)) ## # A tibble: 2 × 2 ##   treatment mean_return ##       <int>       <dbl> ## 1         0      0.0724 ## 2         1      0.0764"},{"path":"/articles/causal-methods-overview.html","id":"propensity-score-matching-psm","dir":"Articles","previous_headings":"","what":"🎯 2. Propensity Score Matching (PSM)","title":"Causal Inference Methods Overview","text":"PSM attempts create balanced dataset matching treated control units probability receiving treatment. Check matched data:","code":"psm <- matchit(treatment ~ market_return + alpha + beta, data = fund_performance, method = \"nearest\") summary(psm) ##  ## Call: ## matchit(formula = treatment ~ market_return + alpha + beta, data = fund_performance,  ##     method = \"nearest\") ##  ## Summary of Balance for All Data: ##               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance             0.4942        0.4919          0.0961     0.9914    0.0250 ## market_return        0.0623        0.0610          0.0134     0.9360    0.0079 ## alpha                0.0102        0.0115         -0.0687     0.9442    0.0194 ## beta                 0.9919        0.9993         -0.0654     0.9965    0.0186 ##               eCDF Max ## distance        0.0725 ## market_return   0.0232 ## alpha           0.0512 ## beta            0.0413 ##  ## Summary of Balance for Matched Data: ##               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance             0.4942        0.4920          0.0887     1.0413    0.0230 ## market_return        0.0623        0.0602          0.0208     0.9314    0.0088 ## alpha                0.0102        0.0113         -0.0568     0.9830    0.0167 ## beta                 0.9919        0.9992         -0.0650     1.0060    0.0185 ##               eCDF Max Std. Pair Dist. ## distance        0.0730          0.0927 ## market_return   0.0243          1.1393 ## alpha           0.0467          0.8110 ## beta            0.0426          0.8197 ##  ## Sample Sizes: ##           Control Treated ## All           507     493 ## Matched       493     493 ## Unmatched      14       0 ## Discarded       0       0 matched_data <- match.data(psm) ggplot(matched_data, aes(x = return, fill = factor(treatment))) +   geom_density(alpha = 0.5) +   labs(title = \"Return Distribution After Matching\", fill = \"Treatment\") +   theme_minimal()"},{"path":"/articles/causal-methods-overview.html","id":"causal-forests-optional","dir":"Articles","previous_headings":"","what":"🌲 3. Causal Forests (Optional)","title":"Causal Inference Methods Overview","text":"can also use advanced estimators like causal forests (via grf package). covered can estimate heterogeneous treatment effects. Install explore : https://grf-labs.github.io/grf/","code":""},{"path":[]},{"path":"/articles/causal-methods-overview.html","id":"citation","dir":"Articles","previous_headings":"","what":"📖 Citation","title":"Causal Inference Methods Overview","text":"","code":"citation(\"CausalInvestData\") ## To cite the CausalInvestData package in publications, use: ##  ##   Conilias Zvobwo E (2025). _CausalInvestData: Simulated Datasets for ##   Causal Inference in Investment Management_. R package version 0.1.0, ##   <https://github.com/edzai/CausalInvestData>. ##  ## A BibTeX entry for LaTeX users is ##  ##   @Manual{, ##     title = {CausalInvestData: Simulated Datasets for Causal Inference in Investment Management}, ##     author = {Edzai {Conilias Zvobwo}}, ##     year = {2025}, ##     note = {R package version 0.1.0}, ##     url = {https://github.com/edzai/CausalInvestData}, ##   }"},{"path":"/articles/covariate-balance-diagnostics.html","id":"covariate-balance-diagnostics","dir":"Articles","previous_headings":"","what":"⚖️ Covariate Balance Diagnostics","title":"Covariate Balance Diagnostics in Causal Inference","text":"Ensuring covariates balanced across treatment groups critical reducing bias causal inference. Diagnostics help verify whether matching weighting strategies achieved .","code":""},{"path":"/articles/covariate-balance-diagnostics.html","id":"simulate-confounded-data","dir":"Articles","previous_headings":"","what":"1. 🧪 Simulate Confounded Data","title":"Covariate Balance Diagnostics in Causal Inference","text":"","code":"set.seed(123) n <- 1000  X1 <- rnorm(n) X2 <- rbinom(n, 1, 0.5) logit_p <- -0.5 + 0.7 * X1 + 1.2 * X2 p_treat <- 1 / (1 + exp(-logit_p)) W <- rbinom(n, 1, p_treat)  Y <- 3 * W + 0.5 * X1 + 0.8 * X2 + rnorm(n) data <- data.frame(X1, X2, W, Y)"},{"path":"/articles/covariate-balance-diagnostics.html","id":"perform-propensity-score-matching","dir":"Articles","previous_headings":"","what":"2. 🎯 Perform Propensity Score Matching","title":"Covariate Balance Diagnostics in Causal Inference","text":"","code":"match_model <- matchit(W ~ X1 + X2, data = data, method = \"nearest\", distance = \"logit\") summary(match_model) ##  ## Call: ## matchit(formula = W ~ X1 + X2, data = data, method = \"nearest\",  ##     distance = \"logit\") ##  ## Summary of Balance for All Data: ##          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance        0.6128        0.4582          0.8838     0.8746    0.2245 ## X1              0.2922       -0.3106          0.6420     0.9700    0.1739 ## X2              0.6125        0.3537          0.5313          .    0.2588 ##          eCDF Max ## distance   0.3342 ## X1         0.2779 ## X2         0.2588 ##  ## Summary of Balance for Matched Data: ##          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance        0.6643        0.4582          1.1782     0.5242    0.3023 ## X1              0.4617       -0.3106          0.8225     0.8641    0.2261 ## X2              0.7096        0.3537          0.7305          .    0.3559 ##          eCDF Max Std. Pair Dist. ## distance   0.4803          1.1782 ## X1         0.3865          1.0319 ## X2         0.3559          0.8829 ##  ## Sample Sizes: ##           Control Treated ## All           458     542 ## Matched       458     458 ## Unmatched       0      84 ## Discarded       0       0"},{"path":"/articles/covariate-balance-diagnostics.html","id":"balance-diagnostics-with-cobalt","dir":"Articles","previous_headings":"","what":"3. 📊 Balance Diagnostics with cobalt","title":"Covariate Balance Diagnostics in Causal Inference","text":"","code":"love.plot(match_model, binary = \"std\", var.order = \"unadjusted\",           abs = TRUE, thresholds = c(m = .1),           title = \"Covariate Balance Before and After Matching\")"},{"path":"/articles/covariate-balance-diagnostics.html","id":"interpreting-balance-metrics","dir":"Articles","previous_headings":"","what":"4. ✅ Interpreting Balance Metrics","title":"Covariate Balance Diagnostics in Causal Inference","text":"Standardized Mean Differences (SMD): < 0.1 considered balanced Look reduction SMD matching Avoid overfitting extreme weights","code":""},{"path":"/articles/covariate-balance-diagnostics.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Covariate Balance Diagnostics in Causal Inference","text":"Austin (2009). Balance diagnostics comparing distribution baseline covariates using standardized differences Stuart (2010). Matching Methods Causal Inference: Review Look Forward","code":""},{"path":"/articles/dags-and-assumptions.html","id":"dags-and-assumptions-in-causal-inference","dir":"Articles","previous_headings":"","what":"🔗 DAGs and Assumptions in Causal Inference","title":"DAGs and Assumptions in Causal Inference","text":"Directed Acyclic Graphs (DAGs) provide powerful way encode assumptions variables system related. help us: - Identify confounders mediators - Test identification strategies - Derive adjustment sets","code":""},{"path":"/articles/dags-and-assumptions.html","id":"define-a-simple-dag","dir":"Articles","previous_headings":"","what":"🎯 Define a Simple DAG","title":"DAGs and Assumptions in Causal Inference","text":"Let’s say ’re estimating effect Treatment Outcome, confounder X.","code":"dag <- dagitty(\"dag {   X -> Treatment   X -> Outcome   Treatment -> Outcome }\")  plot(dag)"},{"path":"/articles/dags-and-assumptions.html","id":"adjustment-sets","dir":"Articles","previous_headings":"","what":"📚 Adjustment Sets","title":"DAGs and Assumptions in Causal Inference","text":"variables need control identify causal effect Treatment Outcome? shows adjusting X sufficient.","code":"adjustmentSets(dag, exposure = \"Treatment\", outcome = \"Outcome\") ## { X }"},{"path":"/articles/dags-and-assumptions.html","id":"more-complex-dag","dir":"Articles","previous_headings":"","what":"🧠 More Complex DAG","title":"DAGs and Assumptions in Causal Inference","text":"","code":"complex_dag <- dagitty(\"dag {   Age -> Treatment   Income -> Treatment   Age -> Outcome   Income -> Outcome   Treatment -> Behavior -> Outcome   unobserved1 [unobserved]   unobserved1 -> Income   unobserved1 -> Outcome }\")  ggdag::ggdag(complex_dag, layout = \"circle\") +   ggtitle(\"DAG with Confounding and Mediation\")"},{"path":"/articles/dags-and-assumptions.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"DAGs and Assumptions in Causal Inference","text":"DAGs help us: - Encode causal assumptions - Identify valid adjustment strategies - Prevent common pitfalls like conditioning colliders Learning draw analyze DAGs core skill causal analyst.","code":""},{"path":"/articles/dags-and-assumptions.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"DAGs and Assumptions in Causal Inference","text":"Textor et al. (2016). dagitty: Graphical Analysis Structural Causal Models Pearl (2009). Causality: Models, Reasoning, Inference","code":""},{"path":"/articles/data-visuals.html","id":"fund-performance-distribution","dir":"Articles","previous_headings":"","what":"📈 Fund Performance Distribution","title":"Dataset Visualizations","text":"","code":"data(\"fund_performance\")  ggplot(fund_performance, aes(x = return, fill = factor(treatment))) +   geom_histogram(alpha = 0.7, bins = 40, position = \"identity\") +   labs(title = \"Distribution of Fund Returns by Treatment\",        x = \"Return\", y = \"Count\", fill = \"Treatment\") +   theme_minimal()"},{"path":"/articles/data-visuals.html","id":"client-behavior-correlation-of-features","dir":"Articles","previous_headings":"","what":"🧮 Client Behavior: Correlation of Features","title":"Dataset Visualizations","text":"","code":"data(\"client_behavior\")  client_behavior %>%   select(age, income, satisfaction_score) %>%   GGally::ggpairs(title = \"Correlation Matrix of Client Features\") ## Registered S3 method overwritten by 'GGally': ##   method from    ##   +.gg   ggplot2"},{"path":"/articles/data-visuals.html","id":"macro-shocks-over-time","dir":"Articles","previous_headings":"","what":"📆 Macro Shocks Over Time","title":"Dataset Visualizations","text":"","code":"data(\"macro_shocks\")  macro_shocks %>%   pivot_longer(cols = c(\"interest_rate\", \"gdp_growth\", \"market_index\")) %>%   ggplot(aes(x = date, y = value, color = name)) +   geom_line() +   facet_wrap(~ name, scales = \"free_y\") +   theme_minimal() +   labs(title = \"Macro Shocks Over Time\", y = \"Value\", x = \"Date\")"},{"path":"/articles/difference-in-differences.html","id":"difference-in-differences-did","dir":"Articles","previous_headings":"","what":"📊 Difference-in-Differences (DiD)","title":"Difference-in-Differences (DiD): Simulated Example","text":"popular method estimate causal effects using panel repeated cross-sectional data treatment applied one group another.","code":""},{"path":"/articles/difference-in-differences.html","id":"simulate-did-setup","dir":"Articles","previous_headings":"","what":"1. ✨ Simulate DiD Setup","title":"Difference-in-Differences (DiD): Simulated Example","text":"","code":"set.seed(123) n <- 1000 group <- rep(c(\"control\", \"treatment\"), each = n/2) time <- rep(c(\"pre\", \"post\"), times = n/2) treated <- ifelse(group == \"treatment\" & time == \"post\", 1, 0)  baseline <- rnorm(n) Y <- 2 * treated + 0.5 * as.numeric(group == \"treatment\") +       0.3 * as.numeric(time == \"post\") + baseline + rnorm(n, 0, 0.5)  df <- data.frame(group, time, treated, Y) head(df) ##     group time treated          Y ## 1 control  pre       0 -1.0583750 ## 2 control post       0 -0.4501550 ## 3 control  pre       0  1.5497182 ## 4 control post       0  0.3044208 ## 5 control  pre       0 -1.1453837 ## 6 control post       0  2.5353517"},{"path":"/articles/difference-in-differences.html","id":"visualize-group-time-means","dir":"Articles","previous_headings":"","what":"2. 📈 Visualize Group-Time Means","title":"Difference-in-Differences (DiD): Simulated Example","text":"","code":"df_summary <- df %>%   group_by(group, time) %>%   summarise(mean_Y = mean(Y), .groups = \"drop\")  ggplot(df_summary, aes(x = time, y = mean_Y, group = group, color = group)) +   geom_line(size = 1.2) +   geom_point(size = 2) +   labs(title = \"Group-Time Averages\", y = \"Mean Outcome\", x = \"Time\") +   theme_minimal()"},{"path":"/articles/difference-in-differences.html","id":"estimate-did-effect","dir":"Articles","previous_headings":"","what":"3. 🧮 Estimate DiD Effect","title":"Difference-in-Differences (DiD): Simulated Example","text":"coefficient group_num:time_num estimate.","code":"df$time_num <- ifelse(df$time == \"post\", 1, 0) df$group_num <- ifelse(df$group == \"treatment\", 1, 0)  did_model <- lm(Y ~ group_num * time_num, data = df) summary(did_model) ##  ## Call: ## lm(formula = Y ~ group_num * time_num, data = df) ##  ## Residuals: ##     Min      1Q  Median      3Q     Max  ## -3.9273 -0.7774  0.0005  0.7100  3.7544  ##  ## Coefficients: ##                    Estimate Std. Error t value Pr(>|t|)     ## (Intercept)         0.11072    0.07285   1.520   0.1288     ## group_num           0.43432    0.10302   4.216 2.71e-05 *** ## time_num            0.17393    0.10302   1.688   0.0917 .   ## group_num:time_num  2.09004    0.14569  14.346  < 2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 1.152 on 996 degrees of freedom ## Multiple R-squared:  0.4742, Adjusted R-squared:  0.4726  ## F-statistic: 299.4 on 3 and 996 DF,  p-value: < 2.2e-16"},{"path":"/articles/difference-in-differences.html","id":"assumptions","dir":"Articles","previous_headings":"","what":"✅ Assumptions","title":"Difference-in-Differences (DiD): Simulated Example","text":"Parallel Trends: Control treatment groups evolve similarly absence treatment Spillover Effects Anticipation","code":""},{"path":"/articles/difference-in-differences.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Difference-in-Differences (DiD): Simulated Example","text":"Angrist & Pischke (2009). Mostly Harmless Econometrics Bertrand, Duflo, Mullainathan (2004). Much Trust Differences--Differences Estimates?","code":""},{"path":"/articles/double-machine-learning.html","id":"double-machine-learning-dml","dir":"Articles","previous_headings":"","what":"🤖 Double Machine Learning (DML)","title":"Double Machine Learning (DML) for Causal Inference","text":"Double Machine Learning (DML) uses flexible machine learning models estimate nuisance parameters (e.g., propensity scores, outcome models) removes bias via orthogonalization, enabling valid causal inference.","code":""},{"path":"/articles/double-machine-learning.html","id":"simulate-data-with-confounding","dir":"Articles","previous_headings":"","what":"1. 🧪 Simulate Data with Confounding","title":"Double Machine Learning (DML) for Causal Inference","text":"","code":"set.seed(123) n <- 1000  X1 <- rnorm(n) X2 <- rnorm(n) W <- rbinom(n, 1, prob = plogis(0.5 * X1 + 0.5 * X2)) Y <- 2 * W + 1.5 * X1 + 1.0 * X2 + rnorm(n)  df <- data.frame(X1, X2, W, Y)"},{"path":[]},{"path":"/articles/double-machine-learning.html","id":"a-split-into-folds","dir":"Articles","previous_headings":"2. 🔍 DML Steps","what":"(a) Split into folds","title":"Double Machine Learning (DML) for Causal Inference","text":"","code":"folds <- createFolds(df$Y, k = 2) train1 <- df[folds[[1]], ] train2 <- df[folds[[2]], ]"},{"path":"/articles/double-machine-learning.html","id":"b-estimate-nuisance-functions","dir":"Articles","previous_headings":"2. 🔍 DML Steps","what":"(b) Estimate nuisance functions","title":"Double Machine Learning (DML) for Causal Inference","text":"","code":"# Outcome model: Y ~ X1 + X2 (train2 on train1) y_model <- cv.glmnet(as.matrix(train1[, c(\"X1\", \"X2\")]), train1$Y) m_Y2 <- predict(y_model, as.matrix(train2[, c(\"X1\", \"X2\")]), s = \"lambda.min\")  # Treatment model: W ~ X1 + X2 w_model <- cv.glmnet(as.matrix(train1[, c(\"X1\", \"X2\")]), train1$W, family = \"binomial\") m_W2 <- predict(w_model, as.matrix(train2[, c(\"X1\", \"X2\")]), s = \"lambda.min\", type = \"response\")"},{"path":"/articles/double-machine-learning.html","id":"c-orthogonalization","dir":"Articles","previous_headings":"2. 🔍 DML Steps","what":"(c) Orthogonalization","title":"Double Machine Learning (DML) for Causal Inference","text":"","code":"res_Y <- train2$Y - m_Y2 res_W <- train2$W - m_W2  alpha_hat <- coef(lm(res_Y ~ res_W))[2] cat(\"Estimated Treatment Effect (DML):\", round(alpha_hat, 3)) ## Estimated Treatment Effect (DML): 1.983"},{"path":"/articles/double-machine-learning.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Double Machine Learning (DML) for Causal Inference","text":"Double Machine Learning: - Uses ML estimate nuisance models (Y|X W|X) - Debiases via residual--residual regression - Yields valid causal estimates flexible modeling","code":""},{"path":"/articles/double-machine-learning.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Double Machine Learning (DML) for Causal Inference","text":"Chernozhukov et al. (2018). Double/Debiased Machine Learning Treatment Structural Parameters Athey & Imbens (2019). Machine Learning Econometrics","code":""},{"path":"/articles/front-door-criterion.html","id":"front-door-criterion-in-causal-inference","dir":"Articles","previous_headings":"","what":"🚪 Front-door Criterion in Causal Inference","title":"Front-door Criterion: Explaining Causal Paths Through Mediators","text":"front-door criterion allows causal identification even unmeasured confounder treatment outcome — provided can observe mediator fully transmits causal path.","code":""},{"path":"/articles/front-door-criterion.html","id":"simulate-front-door-data","dir":"Articles","previous_headings":"","what":"1. 🎯 Simulate Front-door Data","title":"Front-door Criterion: Explaining Causal Paths Through Mediators","text":"","code":"set.seed(42) n <- 1000  U <- rnorm(n)                # Unobserved confounder X <- 0.5 * U + rnorm(n)      # Treatment influenced by U M <- 1.5 * X + rnorm(n)      # Mediator influenced by X Y <- 2 * M + 0.5 * U + rnorm(n)  # Outcome influenced by M and U  df <- data.frame(X, M, Y) head(df) ##            X            M          Y ## 1  3.0105377  4.766384643  9.5325868 ## 2  0.2417731  0.084735594 -0.9055924 ## 3  1.1522976  0.003710699 -0.2180185 ## 4  0.6934047 -0.966597894 -2.7654351 ## 5 -0.7937992 -2.482507183 -3.6471197 ## 6 -0.6505452 -0.609979528 -2.1524781"},{"path":"/articles/front-door-criterion.html","id":"naive-regression-is-biased","dir":"Articles","previous_headings":"","what":"2. ⚠️ Naive Regression is Biased","title":"Front-door Criterion: Explaining Causal Paths Through Mediators","text":"","code":"naive_model <- lm(Y ~ X, data = df) summary(naive_model) ##  ## Call: ## lm(formula = Y ~ X, data = df) ##  ## Residuals: ##     Min      1Q  Median      3Q     Max  ## -7.8508 -1.5715  0.0027  1.4748  7.9338  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) -0.03721    0.07284  -0.511     0.61     ## X            3.21389    0.06561  48.987   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 2.303 on 998 degrees of freedom ## Multiple R-squared:  0.7063, Adjusted R-squared:  0.706  ## F-statistic:  2400 on 1 and 998 DF,  p-value: < 2.2e-16"},{"path":"/articles/front-door-criterion.html","id":"estimate-causal-effect-using-front-door-formula","dir":"Articles","previous_headings":"","what":"3. 🧠 Estimate Causal Effect Using Front-door Formula","title":"Front-door Criterion: Explaining Causal Paths Through Mediators","text":"","code":"model_M_X <- lm(M ~ X, data = df) model_Y_M <- lm(Y ~ M, data = df)  beta_M_X <- coef(model_M_X)[\"X\"] beta_Y_M <- coef(model_Y_M)[\"M\"]  frontdoor_effect <- beta_M_X * beta_Y_M cat(\"Estimated Front-door Effect:\", round(frontdoor_effect, 2)) ## Estimated Front-door Effect: 3.13"},{"path":"/articles/front-door-criterion.html","id":"visualize-causal-chain","dir":"Articles","previous_headings":"","what":"4. 📈 Visualize Causal Chain","title":"Front-door Criterion: Explaining Causal Paths Through Mediators","text":"","code":"ggplot(df, aes(x = X, y = M)) +   geom_point(alpha = 0.4) +   geom_smooth(method = \"lm\", se = FALSE) +   labs(title = \"Path A: Treatment to Mediator\", x = \"Treatment (X)\", y = \"Mediator (M)\") +   theme_minimal() ggplot(df, aes(x = M, y = Y)) +   geom_point(alpha = 0.4) +   geom_smooth(method = \"lm\", se = FALSE) +   labs(title = \"Path B: Mediator to Outcome\", x = \"Mediator (M)\", y = \"Outcome (Y)\") +   theme_minimal()"},{"path":"/articles/front-door-criterion.html","id":"assumptions-for-front-door-identification","dir":"Articles","previous_headings":"","what":"✅ Assumptions for Front-door Identification","title":"Front-door Criterion: Explaining Causal Paths Through Mediators","text":"directed paths X Y go M unmeasured confounders X → M M → Y X must causal effect M","code":""},{"path":"/articles/front-door-criterion.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Front-door Criterion: Explaining Causal Paths Through Mediators","text":"Pearl, J. (2009). Causality: Models, Reasoning, Inference Textor et al. (2016). dagitty: Graphical Analysis Structural Causal Models","code":""},{"path":"/articles/heterogeneous-effects.html","id":"what-are-heterogeneous-treatment-effects","dir":"Articles","previous_headings":"","what":"🧪 What Are Heterogeneous Treatment Effects?","title":"Heterogeneous Treatment Effects","text":"Heterogeneous Treatment Effects (HTEs) occur impact treatment varies across different units subgroups population. financial decision-making, understanding benefits (less) given strategy can useful knowing average effect. ’ll explore using fund_performance dataset.","code":""},{"path":"/articles/heterogeneous-effects.html","id":"load-the-data","dir":"Articles","previous_headings":"","what":"📦 Load the Data","title":"Heterogeneous Treatment Effects","text":"Let’s inspect treatment effects differ levels beta (proxy fund risk exposure):","code":"data(\"fund_performance\") head(fund_performance) ##   fund_id market_return        alpha      beta treatment       return ## 1       1   0.003952435 -0.009915974 0.9217857         0 -0.007775751 ## 2       2   0.036982251 -0.010799101 1.1331275         1  0.032828934 ## 3       3   0.215870831  0.009640395 1.0374590         1  0.224115880 ## 4       4   0.067050839  0.007356497 1.1228787         1  0.080673608 ## 5       5   0.072928774 -0.040986855 0.9176203         0  0.051918971 ## 6       6   0.231506499  0.030811469 0.8564341         0  0.228707376"},{"path":"/articles/heterogeneous-effects.html","id":"stratify-by-fund-beta-quantiles","dir":"Articles","previous_headings":"","what":"📊 Stratify by Fund Beta Quantiles","title":"Heterogeneous Treatment Effects","text":"","code":"fund_performance <- fund_performance %>%   mutate(beta_group = ntile(beta, 3))  # low, medium, high  group_summary <- fund_performance %>%   group_by(beta_group, treatment) %>%   summarise(mean_return = mean(return), .groups = \"drop\")  group_summary %>%   tidyr::pivot_wider(names_from = treatment, values_from = mean_return,                      names_prefix = \"treatment_\") %>%   mutate(estimated_effect = treatment_1 - treatment_0) ## # A tibble: 3 × 4 ##   beta_group treatment_0 treatment_1 estimated_effect ##        <int>       <dbl>       <dbl>            <dbl> ## 1          1      0.0681      0.0801          0.0119  ## 2          2      0.0696      0.0726          0.00305 ## 3          3      0.0791      0.0766         -0.00253"},{"path":"/articles/heterogeneous-effects.html","id":"visualize-treatment-effects-by-risk-exposure","dir":"Articles","previous_headings":"","what":"📈 Visualize Treatment Effects by Risk Exposure","title":"Heterogeneous Treatment Effects","text":"","code":"group_summary %>%   ggplot(aes(x = factor(beta_group), y = mean_return, fill = factor(treatment))) +   geom_col(position = \"dodge\") +   labs(title = \"Returns by Treatment Across Beta Groups\",        x = \"Beta Quantile Group\", y = \"Mean Return\",        fill = \"Treatment\") +   theme_minimal()"},{"path":"/articles/heterogeneous-effects.html","id":"optional-use-causal-forests-grf","dir":"Articles","previous_headings":"","what":"🌲 Optional: Use Causal Forests (grf)","title":"Heterogeneous Treatment Effects","text":"grf package installed, can run:","code":"# Uncomment and install if needed # install.packages(\"grf\")  # library(grf) # X <- fund_performance %>% select(market_return, alpha, beta) # Y <- fund_performance$return # W <- fund_performance$treatment # forest <- causal_forest(X, Y, W) # tau_hat <- predict(forest)$predictions # hist(tau_hat, breaks = 30, main = \"Estimated Treatment Effects (GRF)\", xlab = \"tau_hat\")"},{"path":"/articles/heterogeneous-effects.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Heterogeneous Treatment Effects","text":"Even without advanced ML, subgroup analysis reveals important insights treatments work differently different fund profiles.","code":""},{"path":"/articles/heterogeneous-effects.html","id":"citation","dir":"Articles","previous_headings":"","what":"📖 Citation","title":"Heterogeneous Treatment Effects","text":"","code":"citation(\"CausalInvestData\") ## To cite the CausalInvestData package in publications, use: ##  ##   Conilias Zvobwo E (2025). _CausalInvestData: Simulated Datasets for ##   Causal Inference in Investment Management_. R package version 0.1.0, ##   <https://github.com/edzai/CausalInvestData>. ##  ## A BibTeX entry for LaTeX users is ##  ##   @Manual{, ##     title = {CausalInvestData: Simulated Datasets for Causal Inference in Investment Management}, ##     author = {Edzai {Conilias Zvobwo}}, ##     year = {2025}, ##     note = {R package version 0.1.0}, ##     url = {https://github.com/edzai/CausalInvestData}, ##   }"},{"path":"/articles/instrumental-variables.html","id":"instrumental-variables-with-simulated-data","dir":"Articles","previous_headings":"","what":"🎯 Instrumental Variables with Simulated Data","title":"Instrumental Variables with Simulated Data","text":"Instrumental Variables (IV) help identify causal effects unobserved confounding. instrument affects treatment direct path outcome.","code":""},{"path":"/articles/instrumental-variables.html","id":"simulate-confounded-data","dir":"Articles","previous_headings":"","what":"1. 🧪 Simulate Confounded Data","title":"Instrumental Variables with Simulated Data","text":"","code":"set.seed(123) n <- 1000  U <- rnorm(n)  # unobserved confounder Z <- rbinom(n, 1, 0.5)  # instrument X <- 0.5 * Z + 0.7 * U + rnorm(n)  # treatment, influenced by instrument and confounder Y <- 2 * X + 1 * U + rnorm(n)      # outcome, influenced by treatment and confounder  data <- data.frame(Y, X, Z, U) head(data) ##            Y          X Z           U ## 1 -3.6659226 -1.2133196 0 -0.56047565 ## 2 -0.5926277 -0.4683815 0 -0.23017749 ## 3  1.2321894  0.1889978 0  1.55870831 ## 4  1.8893736  1.1764246 1  0.07050839 ## 5  3.3253852  1.2108564 0  0.12928774 ## 6  8.8949617  3.8277590 1  1.71506499"},{"path":"/articles/instrumental-variables.html","id":"ols-is-biased-due-to-unobserved-confounding","dir":"Articles","previous_headings":"","what":"2. ⚠️ OLS is Biased Due to Unobserved Confounding","title":"Instrumental Variables with Simulated Data","text":"","code":"ols_model <- lm(Y ~ X, data = data) summary(ols_model) ##  ## Call: ## lm(formula = Y ~ X, data = data) ##  ## Residuals: ##     Min      1Q  Median      3Q     Max  ## -4.4015 -0.8701 -0.0011  0.8749  4.0078  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) -0.09824    0.04145   -2.37    0.018 *   ## X            2.44974    0.03357   72.97   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 1.283 on 998 degrees of freedom ## Multiple R-squared:  0.8421, Adjusted R-squared:  0.842  ## F-statistic:  5324 on 1 and 998 DF,  p-value: < 2.2e-16"},{"path":"/articles/instrumental-variables.html","id":"use-iv-estimate-via-ivreg","dir":"Articles","previous_headings":"","what":"3. ✅ Use IV: Estimate via ivreg","title":"Instrumental Variables with Simulated Data","text":"","code":"iv_model <- ivreg(Y ~ X | Z, data = data) summary(iv_model) ##  ## Call: ## ivreg(formula = Y ~ X | Z, data = data) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -4.30901 -0.88235  0.01353  0.94421  4.46543  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) -0.01573    0.05564  -0.283    0.777     ## X            2.12700    0.14094  15.091   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 1.341 on 998 degrees of freedom ## Multiple R-Squared: 0.8275,  Adjusted R-squared: 0.8274  ## Wald test: 227.7 on 1 and 998 DF,  p-value: < 2.2e-16"},{"path":"/articles/instrumental-variables.html","id":"visualize-the-first-stage-z-x","dir":"Articles","previous_headings":"","what":"4. 📊 Visualize the First Stage (Z → X)","title":"Instrumental Variables with Simulated Data","text":"","code":"ggplot(data, aes(x = factor(Z), y = X)) +   geom_boxplot(fill = \"skyblue\") +   labs(title = \"First Stage: Instrument Z Effect on Treatment X\", x = \"Instrument (Z)\", y = \"Treatment (X)\") +   theme_minimal()"},{"path":"/articles/instrumental-variables.html","id":"iv-assumptions-recap","dir":"Articles","previous_headings":"","what":"5. ✅ IV Assumptions Recap","title":"Instrumental Variables with Simulated Data","text":"Relevance: Z correlated X ✔️ Exclusion Restriction: Z directly affect Y ❌ (U must affected Z) Independence: Z independent unmeasured confounders (U)","code":""},{"path":[]},{"path":"/articles/instrumental-variables.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Instrumental Variables with Simulated Data","text":"Angrist & Pischke (2009). Mostly Harmless Econometrics Wooldridge (2010). Econometric Analysis Cross Section Panel Data","code":""},{"path":"/articles/intro.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Introduction to CausalInvestData","text":"CausalInvestData provides simulated datasets causal inference institutional investment management. package includes four core datasets designed reflect real-world structures, enabling users prototype, teach, evaluate methods propensity score matching, causal forests, impact analysis.","code":""},{"path":"/articles/intro.html","id":"dataset-fund_performance","dir":"Articles","previous_headings":"","what":"Dataset: fund_performance","title":"Introduction to CausalInvestData","text":"","code":"data(\"fund_performance\", package = \"CausalInvestData\") head(fund_performance) ##   fund_id market_return        alpha      beta treatment       return ## 1       1   0.003952435 -0.009915974 0.9217857         0 -0.007775751 ## 2       2   0.036982251 -0.010799101 1.1331275         1  0.032828934 ## 3       3   0.215870831  0.009640395 1.0374590         1  0.224115880 ## 4       4   0.067050839  0.007356497 1.1228787         1  0.080673608 ## 5       5   0.072928774 -0.040986855 0.9176203         0  0.051918971 ## 6       6   0.231506499  0.030811469 0.8564341         0  0.228707376"},{"path":"/articles/intro.html","id":"propensity-score-matching-example","dir":"Articles","previous_headings":"Dataset: fund_performance","what":"Propensity Score Matching Example","title":"Introduction to CausalInvestData","text":"","code":"library(MatchIt) ## Warning: package 'MatchIt' was built under R version 4.3.3 m.out <- matchit(treatment ~ market_return + alpha + beta, data = fund_performance) summary(m.out) ##  ## Call: ## matchit(formula = treatment ~ market_return + alpha + beta, data = fund_performance) ##  ## Summary of Balance for All Data: ##               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance             0.4942        0.4919          0.0961     0.9914    0.0250 ## market_return        0.0623        0.0610          0.0134     0.9360    0.0079 ## alpha                0.0102        0.0115         -0.0687     0.9442    0.0194 ## beta                 0.9919        0.9993         -0.0654     0.9965    0.0186 ##               eCDF Max ## distance        0.0725 ## market_return   0.0232 ## alpha           0.0512 ## beta            0.0413 ##  ## Summary of Balance for Matched Data: ##               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean ## distance             0.4942        0.4920          0.0887     1.0413    0.0230 ## market_return        0.0623        0.0602          0.0208     0.9314    0.0088 ## alpha                0.0102        0.0113         -0.0568     0.9830    0.0167 ## beta                 0.9919        0.9992         -0.0650     1.0060    0.0185 ##               eCDF Max Std. Pair Dist. ## distance        0.0730          0.0927 ## market_return   0.0243          1.1393 ## alpha           0.0467          0.8110 ## beta            0.0426          0.8197 ##  ## Sample Sizes: ##           Control Treated ## All           507     493 ## Matched       493     493 ## Unmatched      14       0 ## Discarded       0       0"},{"path":"/articles/intro.html","id":"dataset-portfolio_allocations","dir":"Articles","previous_headings":"","what":"Dataset: portfolio_allocations","title":"Introduction to CausalInvestData","text":"","code":"data(\"portfolio_allocations\", package = \"CausalInvestData\") head(portfolio_allocations) ##   portfolio_id risk_level equity_allocation treatment     return ## 1            1        Low         0.4080645         1 0.06659800 ## 2            2       High         0.7138592         1 0.09565076 ## 3            3     Medium         0.7284506         1 0.07306955 ## 4            4       High         0.2891309         1 0.09795321 ## 5            5        Low         0.8376339         0 0.10054662 ## 6            6     Medium         0.4115289         1 0.08804457 ##   bond_allocation ## 1       0.5919355 ## 2       0.2861408 ## 3       0.2715494 ## 4       0.7108691 ## 5       0.1623661 ## 6       0.5884711"},{"path":"/articles/intro.html","id":"dataset-client_behavior","dir":"Articles","previous_headings":"","what":"Dataset: client_behavior","title":"Introduction to CausalInvestData","text":"","code":"data(\"client_behavior\", package = \"CausalInvestData\") head(client_behavior) ##   client_id age   income satisfaction_score treatment churned ## 1         1  54 65785.65           4.898391         0       0 ## 2         2  66 56907.43           2.481101         1       1 ## 3         3  32 57223.12           2.072351         0       0 ## 4         4  48 49584.93           6.903271         0       0 ## 5         5  75 46669.48           3.650145         0       0 ## 6         6  33 52759.41           1.038131         1       0"},{"path":"/articles/intro.html","id":"dataset-macro_shocks","dir":"Articles","previous_headings":"","what":"Dataset: macro_shocks","title":"Introduction to CausalInvestData","text":"","code":"data(\"macro_shocks\", package = \"CausalInvestData\") head(macro_shocks) ##         date interest_rate gdp_growth market_index ## 1 2020-01-01    0.04858548 0.02098241   0.03418012 ## 2 2020-02-01    0.03740164 0.02505696   0.05356738 ## 3 2020-03-01    0.04924685 0.02460699   0.04155380 ## 4 2020-04-01    0.05109889 0.01260686   0.01707771 ## 5 2020-05-01    0.02392792 0.02387595   0.02444632 ## 6 2020-06-01    0.06718417 0.01306215  -0.04220713"},{"path":"/articles/intro.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Introduction to CausalInvestData","text":"package ideal : Financial data scientists building causal ML pipelines Academics teaching causal inference methods Practitioners evaluating financial interventions cite package, run:","code":"citation(\"CausalInvestData\") ## To cite the CausalInvestData package in publications, use: ##  ##   Conilias Zvobwo E (2025). _CausalInvestData: Simulated Datasets for ##   Causal Inference in Investment Management_. R package version 0.1.0, ##   <https://github.com/edzai/CausalInvestData>. ##  ## A BibTeX entry for LaTeX users is ##  ##   @Manual{, ##     title = {CausalInvestData: Simulated Datasets for Causal Inference in Investment Management}, ##     author = {Edzai {Conilias Zvobwo}}, ##     year = {2025}, ##     note = {R package version 0.1.0}, ##     url = {https://github.com/edzai/CausalInvestData}, ##   }"},{"path":"/articles/natural-experiments.html","id":"natural-experiments-in-causal-inference","dir":"Articles","previous_headings":"","what":"🌍 Natural Experiments in Causal Inference","title":"Natural Experiments and Quasi-Random Variation","text":"Natural experiments use external, unplanned variation estimate causal effects randomization possible. Examples include policy changes, eligibility cutoffs, geographic variation.","code":""},{"path":"/articles/natural-experiments.html","id":"simulate-a-sharp-cutoff-e-g--policy-eligibility-at-age-60","dir":"Articles","previous_headings":"","what":"1. 🎯 Simulate a Sharp Cutoff (e.g., policy eligibility at age 60)","title":"Natural Experiments and Quasi-Random Variation","text":"","code":"set.seed(42) n <- 1000 age <- runif(n, 50, 70) treatment <- ifelse(age >= 60, 1, 0) noise <- rnorm(n) Y <- 3 * treatment + 0.1 * age + noise  # treatment has causal effect of 3  df <- data.frame(age, treatment, Y) head(df) ##        age treatment         Y ## 1 68.29612         1 10.858753 ## 2 68.74151         1 10.788926 ## 3 55.72279         0  5.569823 ## 4 66.60895         1  9.796905 ## 5 62.83491         1  8.563337 ## 6 60.38192         1  8.840068"},{"path":"/articles/natural-experiments.html","id":"visualize-the-discontinuity","dir":"Articles","previous_headings":"","what":"2. 📊 Visualize the Discontinuity","title":"Natural Experiments and Quasi-Random Variation","text":"","code":"ggplot(df, aes(x = age, y = Y, color = factor(treatment))) +   geom_point(alpha = 0.5) +   geom_smooth(method = \"lm\", se = FALSE) +   geom_vline(xintercept = 60, linetype = \"dashed\", color = \"red\") +   labs(title = \"Sharp Regression Discontinuity at Age 60\",        x = \"Age\", y = \"Outcome\", color = \"Treatment\") +   theme_minimal()"},{"path":"/articles/natural-experiments.html","id":"estimate-local-treatment-effect-near-cutoff","dir":"Articles","previous_headings":"","what":"3. 🧪 Estimate Local Treatment Effect Near Cutoff","title":"Natural Experiments and Quasi-Random Variation","text":"","code":"local_data <- df %>% filter(age >= 58 & age <= 62) rd_model <- lm(Y ~ treatment + age, data = local_data) summary(rd_model) ##  ## Call: ## lm(formula = Y ~ treatment + age, data = local_data) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -2.59404 -0.58844  0.05258  0.59860  2.61584  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) 5.570704   7.148219   0.779    0.437     ## treatment   3.304646   0.263174  12.557   <2e-16 *** ## age         0.005634   0.120973   0.047    0.963     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.9587 on 199 degrees of freedom ## Multiple R-squared:  0.7517, Adjusted R-squared:  0.7492  ## F-statistic: 301.2 on 2 and 199 DF,  p-value: < 2.2e-16"},{"path":"/articles/natural-experiments.html","id":"assumptions-of-rd-design","dir":"Articles","previous_headings":"","what":"4. ✅ Assumptions of RD Design","title":"Natural Experiments and Quasi-Random Variation","text":"manipulation around cutoff (check density) Continuity covariates potential outcomes Precise cutoff assignment","code":""},{"path":"/articles/natural-experiments.html","id":"real-world-examples","dir":"Articles","previous_headings":"","what":"5. 📚 Real-World Examples","title":"Natural Experiments and Quasi-Random Variation","text":"🎓 College access based test scores 💼 Job subsidies based firm size 💊 Treatment access based age income cutoffs","code":""},{"path":"/articles/natural-experiments.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Natural Experiments and Quasi-Random Variation","text":"Natural experiments leverage real-world variation estimate causal effects. sharp regression discontinuity design mimics randomization near cutoff provides credible causal estimates. robust tools, explore rdrobust, rdd, rdpower packages.","code":""},{"path":"/articles/natural-experiments.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Natural Experiments and Quasi-Random Variation","text":"Imbens & Lemieux (2008). Regression Discontinuity Designs: Guide Practice Angrist & Pischke (2009). Mostly Harmless Econometrics","code":""},{"path":"/articles/propensity-score-weighting.html","id":"propensity-score-weighting-psw","dir":"Articles","previous_headings":"","what":"⚖️ Propensity Score Weighting (PSW)","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"PSW technique used adjust confounding observational studies reweighting units based estimated probability receiving treatment.","code":""},{"path":"/articles/propensity-score-weighting.html","id":"simulate-confounded-data","dir":"Articles","previous_headings":"","what":"1. 🧪 Simulate Confounded Data","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"","code":"set.seed(123) n <- 1000  X1 <- rnorm(n) X2 <- rbinom(n, 1, 0.5) logit_p <- -0.5 + 0.7 * X1 + 1.2 * X2 p_treat <- 1 / (1 + exp(-logit_p)) W <- rbinom(n, 1, p_treat)  # True treatment effect is 3 Y <- 3 * W + 0.5 * X1 + 0.8 * X2 + rnorm(n)  data <- data.frame(X1, X2, W, Y) head(data) ##            X1 X2 W          Y ## 1 -0.56047565  0 0 -0.7918415 ## 2 -0.23017749  0 1  3.1218491 ## 3  1.55870831  0 1  3.2377650 ## 4  0.07050839  1 1  5.0544818 ## 5  0.12928774  0 0  0.2387797 ## 6  1.71506499  1 1  4.0422642"},{"path":"/articles/propensity-score-weighting.html","id":"estimate-propensity-scores","dir":"Articles","previous_headings":"","what":"2. 🎯 Estimate Propensity Scores","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"","code":"ps_model <- glm(W ~ X1 + X2, data = data, family = binomial()) data$pscore <- predict(ps_model, type = \"response\")"},{"path":"/articles/propensity-score-weighting.html","id":"compute-weights-inverse-probability-of-treatment-weights","dir":"Articles","previous_headings":"","what":"3. ⚖️ Compute Weights (Inverse Probability of Treatment Weights)","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"","code":"data$wt <- ifelse(data$W == 1, 1 / data$pscore, 1 / (1 - data$pscore)) summary(data$wt) ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  ##   1.047   1.377   1.671   1.996   2.268   9.854"},{"path":"/articles/propensity-score-weighting.html","id":"estimate-weighted-treatment-effect","dir":"Articles","previous_headings":"","what":"4. 🧮 Estimate Weighted Treatment Effect","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"","code":"design <- svydesign(ids = ~1, weights = ~wt, data = data) model_psw <- svyglm(Y ~ W, design = design) summary(model_psw) ##  ## Call: ## svyglm(formula = Y ~ W, design = design) ##  ## Survey design: ## svydesign(ids = ~1, weights = ~wt, data = data) ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept)  0.37767    0.05965   6.331 3.67e-10 *** ## W            2.99871    0.08407  35.671  < 2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for gaussian family taken to be 1.307041) ##  ## Number of Fisher Scoring iterations: 2"},{"path":"/articles/propensity-score-weighting.html","id":"visualize-propensity-score-overlap","dir":"Articles","previous_headings":"","what":"5. 📊 Visualize Propensity Score Overlap","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"","code":"ggplot(data, aes(x = pscore, fill = factor(W))) +   geom_density(alpha = 0.5) +   labs(title = \"Propensity Score Distribution by Treatment\",        x = \"Propensity Score\", fill = \"Treatment\") +   theme_minimal()"},{"path":"/articles/propensity-score-weighting.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"PSW reduces confounding balancing covariates across treatment groups, allowing us estimate causal effects non-randomized data.","code":""},{"path":"/articles/propensity-score-weighting.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Propensity Score Weighting (PSW) for Causal Inference","text":"Rosenbaum & Rubin (1983). Central Role Propensity Score Observational Studies Stuart (2010). Matching Methods Causal Inference: Review Look Forward","code":""},{"path":"/articles/sensitivity-analysis.html","id":"sensitivity-analysis-why-it-matters","dir":"Articles","previous_headings":"","what":"🎯 Sensitivity Analysis: Why It Matters","title":"Sensitivity Analysis: How Robust Is Your Causal Inference?","text":"Even using careful matching regression, unobserved confounding may bias treatment effect estimates. Sensitivity analysis helps us quantify much unobserved bias required nullify results.","code":""},{"path":"/articles/sensitivity-analysis.html","id":"simulate-confounded-data","dir":"Articles","previous_headings":"","what":"1. 🧪 Simulate Confounded Data","title":"Sensitivity Analysis: How Robust Is Your Causal Inference?","text":"","code":"set.seed(123) n <- 1000  U <- rnorm(n)  # unobserved confounder X <- rbinom(n, 1, prob = plogis(0.3 * U))  # treatment depends on U Y <- 2 * X + 1.5 * U + rnorm(n)  # outcome depends on X and U  data <- data.frame(X, Y, U)"},{"path":"/articles/sensitivity-analysis.html","id":"naive-regression-no-u-adjustment","dir":"Articles","previous_headings":"","what":"2. ⚠️ Naive Regression (No U Adjustment)","title":"Sensitivity Analysis: How Robust Is Your Causal Inference?","text":"","code":"naive_model <- lm(Y ~ X, data = data) summary(naive_model) ##  ## Call: ## lm(formula = Y ~ X, data = data) ##  ## Residuals: ##     Min      1Q  Median      3Q     Max  ## -5.5542 -1.2648  0.0258  1.1609  5.8993  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) -0.09461    0.07598  -1.245    0.213     ## X            2.24198    0.10967  20.444   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 1.733 on 998 degrees of freedom ## Multiple R-squared:  0.2952, Adjusted R-squared:  0.2945  ## F-statistic:   418 on 1 and 998 DF,  p-value: < 2.2e-16"},{"path":"/articles/sensitivity-analysis.html","id":"true-model-with-u-for-comparison","dir":"Articles","previous_headings":"","what":"3. 📏 True Model with U (for comparison)","title":"Sensitivity Analysis: How Robust Is Your Causal Inference?","text":"","code":"true_model <- lm(Y ~ X + U, data = data) summary(true_model) ##  ## Call: ## lm(formula = Y ~ X + U, data = data) ##  ## Residuals: ##     Min      1Q  Median      3Q     Max  ## -3.0533 -0.6312 -0.0234  0.6837  3.2464  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) 0.005461   0.043212   0.126    0.899     ## X           1.984994   0.062544  31.737   <2e-16 *** ## U           1.443323   0.031525  45.784   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.9841 on 997 degrees of freedom ## Multiple R-squared:  0.7728, Adjusted R-squared:  0.7724  ## F-statistic:  1696 on 2 and 997 DF,  p-value: < 2.2e-16"},{"path":"/articles/sensitivity-analysis.html","id":"sensitivity-with-manual-bias-factor","dir":"Articles","previous_headings":"","what":"4. 📉 Sensitivity with Manual Bias Factor","title":"Sensitivity Analysis: How Robust Is Your Causal Inference?","text":"’ll manually simulate adding different levels confounding changes treatment effect:","code":"bias_sim <- data.frame(   rho = seq(0, 1, by = 0.05) ) %>%   mutate(     bias = rho * sd(U),     adjusted_beta = coef(naive_model)[[\"X\"]] - bias   )  ggplot(bias_sim, aes(x = rho, y = adjusted_beta)) +   geom_line(color = \"steelblue\", size = 1) +   geom_hline(yintercept = coef(true_model)[[\"X\"]], linetype = \"dashed\", color = \"red\") +   labs(title = \"Effect of Unobserved Confounding on Estimated Treatment Effect\",        x = \"Assumed Correlation with U (rho)\", y = \"Adjusted Beta for X\") +   theme_minimal()"},{"path":"/articles/sensitivity-analysis.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Sensitivity Analysis: How Robust Is Your Causal Inference?","text":"Sensitivity analysis gives us range possible estimates different assumptions unobserved confounders. helps answer: “strong unobserved confounding need explain away effect?”","code":""},{"path":"/articles/sensitivity-analysis.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Sensitivity Analysis: How Robust Is Your Causal Inference?","text":"Cinelli & Hazlett (2020). Making sense sensitivity: Extending omitted variable bias. Rosenbaum (2002). Observational Studies.","code":""},{"path":"/articles/simulate-causal-data.html","id":"why-simulate-causal-data","dir":"Articles","previous_headings":"","what":"🧪 Why Simulate Causal Data?","title":"Simulating Causal Data: A Step-by-Step Guide","text":"Simulating data helps us validate assumptions understand behavior causal estimators controlled conditions. ’s also great tool teaching.","code":""},{"path":"/articles/simulate-causal-data.html","id":"simulate-covariates","dir":"Articles","previous_headings":"","what":"1. 🎲 Simulate Covariates","title":"Simulating Causal Data: A Step-by-Step Guide","text":"","code":"set.seed(123) n <- 1000  X1 <- rnorm(n, mean = 50, sd = 10)       # Age X2 <- rbinom(n, 1, 0.5)                  # Gender (0/1) X3 <- rnorm(n, mean = 50000, sd = 15000) # Income  covariates <- data.frame(X1, X2, X3) head(covariates) ##         X1 X2       X3 ## 1 44.39524  0 37685.20 ## 2 47.69823  0 45391.14 ## 3 65.58708  0 36468.53 ## 4 50.70508  1 59406.03 ## 5 51.29288  0 66805.33 ## 6 67.15065  1 81908.20"},{"path":"/articles/simulate-causal-data.html","id":"simulate-treatment-assignment","dir":"Articles","previous_headings":"","what":"2. 🧮 Simulate Treatment Assignment","title":"Simulating Causal Data: A Step-by-Step Guide","text":"use logistic model treatment assignment based covariates:","code":"logit <- -3 + 0.05 * X1 + 0.8 * X2 - 0.00002 * X3 prob_treat <- 1 / (1 + exp(-logit)) W <- rbinom(n, 1, prob_treat)"},{"path":"/articles/simulate-causal-data.html","id":"define-potential-outcomes","dir":"Articles","previous_headings":"","what":"3. ✨ Define Potential Outcomes","title":"Simulating Causal Data: A Step-by-Step Guide","text":"","code":"Y0 <- 0.5 * X1 + 2 * X2 + rnorm(n, 0, 5) Y1 <- Y0 + 5  # Treatment adds 5 units"},{"path":"/articles/simulate-causal-data.html","id":"create-observed-outcome","dir":"Articles","previous_headings":"","what":"4. 📊 Create Observed Outcome","title":"Simulating Causal Data: A Step-by-Step Guide","text":"","code":"Y_obs <- ifelse(W == 1, Y1, Y0)  data <- covariates %>%   mutate(treatment = W,          Y0 = Y0,          Y1 = Y1,          Y_obs = Y_obs)  head(data) ##         X1 X2       X3 treatment       Y0       Y1    Y_obs ## 1 44.39524  0 37685.20         0 21.44608 26.44608 21.44608 ## 2 47.69823  0 45391.14         1 22.21033 27.21033 27.21033 ## 3 65.58708  0 36468.53         1 25.55272 30.55272 30.55272 ## 4 50.70508  1 59406.03         0 23.86612 28.86612 23.86612 ## 5 51.29288  0 66805.33         0 38.63889 43.63889 38.63889 ## 6 67.15065  1 81908.20         0 35.38825 40.38825 35.38825"},{"path":"/articles/simulate-causal-data.html","id":"estimate-true-vs--observed-effects","dir":"Articles","previous_headings":"","what":"5. 📏 Estimate True vs. Observed Effects","title":"Simulating Causal Data: A Step-by-Step Guide","text":"","code":"true_ate <- mean(Y1 - Y0) est_ate <- mean(data$Y_obs[data$treatment == 1]) - mean(data$Y_obs[data$treatment == 0])  cat(\"True ATE:\", round(true_ate, 2), \"\\n\") ## True ATE: 5 cat(\"Estimated ATE (unadjusted):\", round(est_ate, 2), \"\\n\") ## Estimated ATE (unadjusted): 7.9"},{"path":"/articles/simulate-causal-data.html","id":"visualize-propensity-score-overlap","dir":"Articles","previous_headings":"","what":"6. 📉 Visualize Propensity Score Overlap","title":"Simulating Causal Data: A Step-by-Step Guide","text":"","code":"data$prop_score <- prob_treat  ggplot(data, aes(x = prop_score, fill = factor(treatment))) +   geom_density(alpha = 0.5) +   labs(title = \"Propensity Score Overlap\",        x = \"Propensity Score\", fill = \"Treatment\") +   theme_minimal()"},{"path":"/articles/simulate-causal-data.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Simulating Causal Data: A Step-by-Step Guide","text":"created: - Covariates - Treatment assignment (non-random) - Two potential outcomes (Y0, Y1) - Observed outcomes - ATE comparison Simulating data helps test models, teach concepts, better understand bias variance causal analysis.","code":""},{"path":"/articles/simulate-causal-data.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Simulating Causal Data: A Step-by-Step Guide","text":"Hernán & Robins (2020). Causal Inference: . Pearl (2009). Causality.","code":""},{"path":"/articles/synthetic-control-methods.html","id":"synthetic-control-methods","dir":"Articles","previous_headings":"","what":"🧪 Synthetic Control Methods","title":"Synthetic Control Methods for Policy Evaluation","text":"Synthetic Control Methods (SCM) estimate effect intervention comparing treated unit weighted combination control units best resemble pre-treatment period.","code":""},{"path":"/articles/synthetic-control-methods.html","id":"simulate-panel-data","dir":"Articles","previous_headings":"","what":"1. ✨ Simulate Panel Data","title":"Synthetic Control Methods for Policy Evaluation","text":"","code":"set.seed(123) n_units <- 10 n_years <- 20  unit <- rep(1:n_units, each = n_years) year <- rep(2000:2019, times = n_units) treated <- ifelse(unit == 1 & year >= 2010, 1, 0)  # treatment begins in 2010 for unit 1  # Common trend + unit effects alpha <- rnorm(n_units, 0, 1) trend <- 0.5 * (year - 2000) error <- rnorm(n_units * n_years)  Y <- 5 + alpha[unit] + trend + treated * 3 + error  df <- data.frame(unit = as.factor(unit), year, treated, Y) head(df) ##   unit year treated        Y ## 1    1 2000       0 5.663606 ## 2    1 2001       0 5.299338 ## 3    1 2002       0 5.840296 ## 4    1 2003       0 6.050207 ## 5    1 2004       0 5.883683 ## 6    1 2005       0 8.726437"},{"path":"/articles/synthetic-control-methods.html","id":"plot-treated-vs--controls-over-time","dir":"Articles","previous_headings":"","what":"2. 📈 Plot Treated vs. Controls Over Time","title":"Synthetic Control Methods for Policy Evaluation","text":"","code":"ggplot(df, aes(x = year, y = Y, group = unit, color = unit == 1)) +   geom_line() +   labs(title = \"Treated Unit vs Controls Over Time\", color = \"Treated\") +   theme_minimal()"},{"path":"/articles/synthetic-control-methods.html","id":"synthetic-control-with-pre-treatment-matching","dir":"Articles","previous_headings":"","what":"3. 🧮 Synthetic Control with Pre-treatment Matching","title":"Synthetic Control Methods for Policy Evaluation","text":"’s simplified SCM approach: match pre-treatment means.","code":"df_pre <- df %>% filter(year < 2010) df_post <- df %>% filter(year >= 2010)  avg_pre <- df_pre %>% group_by(unit) %>% summarise(mean_pre = mean(Y)) weights <- avg_pre %>% filter(unit != 1) %>%   mutate(weight = 1 / abs(mean_pre - avg_pre$mean_pre[1])) %>%   mutate(weight = weight / sum(weight))  synth_post <- df_post %>%   filter(unit != 1) %>%   left_join(weights, by = \"unit\") %>%   group_by(year) %>%   summarise(synth_Y = sum(Y * weight))  actual_post <- df_post %>% filter(unit == 1) %>% select(year, Y)  synth_df <- left_join(actual_post, synth_post, by = \"year\")"},{"path":"/articles/synthetic-control-methods.html","id":"plot-synthetic-vs--treated","dir":"Articles","previous_headings":"","what":"4. 📊 Plot Synthetic vs. Treated","title":"Synthetic Control Methods for Policy Evaluation","text":"","code":"ggplot(synth_df, aes(x = year)) +   geom_line(aes(y = Y), color = \"blue\", size = 1.2) +   geom_line(aes(y = synth_Y), color = \"orange\", linetype = \"dashed\", size = 1.2) +   labs(title = \"Synthetic Control vs Treated Unit (Post-2010)\", y = \"Outcome\", x = \"Year\") +   theme_minimal()"},{"path":"/articles/synthetic-control-methods.html","id":"summary","dir":"Articles","previous_headings":"","what":"✅ Summary","title":"Synthetic Control Methods for Policy Evaluation","text":"Synthetic Control Methods: - Create data-driven counterfactual - especially useful policy evaluation - Can extended using Synth, tidysynth, Bayesian SCM tools","code":""},{"path":"/articles/synthetic-control-methods.html","id":"references","dir":"Articles","previous_headings":"","what":"📖 References","title":"Synthetic Control Methods for Policy Evaluation","text":"Abadie, Diamond & Hainmueller (2010). Synthetic Control Methods Comparative Case Studies Abadie (2021). Using Synthetic Controls Causal Inference","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Edzai Conilias Zvobwo. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Conilias Zvobwo E (2025). CausalInvestData: Simulated Datasets Causal Inference Investment Management. R package version 0.1.0, https://github.com/edzai/CausalInvestData.","code":"@Manual{,   title = {CausalInvestData: Simulated Datasets for Causal Inference in Investment Management},   author = {Edzai {Conilias Zvobwo}},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/edzai/CausalInvestData}, }"},{"path":"/index.html","id":"welcome-to-causalinvestdata","dir":"","previous_headings":"","what":"CausalInvestData","title":"CausalInvestData","text":"CausalInvestData open-source R package provides realistic, simulated datasets applying evaluating causal inference methods context institutional investment management. Whether ’re educator, data scientist, policy analyst, datasets help : - Prototype matching models (e.g. PSM) - Estimate treatment effects using real-world structures - Visualize economic shocks portfolio behavior","code":""},{"path":"/index.html","id":"mag-whats-inside","dir":"","previous_headings":"","what":"🔍 What’s Inside?","title":"CausalInvestData","text":"fund_performance: Returns, alpha/beta, treatment outcomes portfolio_allocations: Strategic weights outcomes risk client_behavior: Demographics, satisfaction, churn, advice macro_shocks: Interest rates, GDP, market indices time","code":""},{"path":"/index.html","id":"open_book-learn-by-doing","dir":"","previous_headings":"","what":"📖 Learn by Doing","title":"CausalInvestData","text":"Explore articles: - Introduction - Dataset Visualizations - Causal Inference Methods","code":""},{"path":"/index.html","id":"chart_with_upwards_trend-built-by-edzai-zvobwo","dir":"","previous_headings":"","what":"📈 Built by Edzai Zvobwo","title":"CausalInvestData","text":"package maintained Edzai Zvobwo support education, analytics, digital infrastructure financial professionals across Africa beyond.","code":""},{"path":"/reference/client_behavior.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Client Behavior Data — client_behavior","title":"Simulated Client Behavior Data — client_behavior","text":"dataset simulates client characteristics outcomes satisfaction churn.","code":""},{"path":"/reference/client_behavior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Client Behavior Data — client_behavior","text":"","code":"data(client_behavior)"},{"path":"/reference/client_behavior.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated Client Behavior Data — client_behavior","text":"data frame 1000 observations 6 variables: client_id Client identifier age Client age income Annual income satisfaction_score Score 1 10 treatment Indicator advisory treatment churned Whether client churned (1) (0)","code":""},{"path":"/reference/fund_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Fund Performance Data — fund_performance","title":"Simulated Fund Performance Data — fund_performance","text":"dataset simulates mutual fund performance including treatment effects active allocation strategies.","code":""},{"path":"/reference/fund_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Fund Performance Data — fund_performance","text":"","code":"fund_performance"},{"path":"/reference/fund_performance.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated Fund Performance Data — fund_performance","text":"data frame 1000 rows 6 variables: fund_id Unique identifier market_return Simulated market return alpha Excess return independent market beta Market sensitivity treatment Binary indicator fund strategy treatment return Observed return post-treatment","code":""},{"path":"/reference/macro_shocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Macroeconomic Shocks Time Series — macro_shocks","title":"Simulated Macroeconomic Shocks Time Series — macro_shocks","text":"time-series dataset macroeconomic variables affecting institutional returns.","code":""},{"path":"/reference/macro_shocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Macroeconomic Shocks Time Series — macro_shocks","text":"","code":"data(macro_shocks)"},{"path":"/reference/macro_shocks.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated Macroeconomic Shocks Time Series — macro_shocks","text":"data frame 120 monthly observations: date Monthly observation date interest_rate Simulated interest rate gdp_growth GDP growth rate market_index Cumulative index market performance","code":""},{"path":"/reference/portfolio_allocations.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Portfolio Allocation Data — portfolio_allocations","title":"Simulated Portfolio Allocation Data — portfolio_allocations","text":"dataset simulates portfolio allocations returns based risk profiles treatment exposure.","code":""},{"path":"/reference/portfolio_allocations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Portfolio Allocation Data — portfolio_allocations","text":"","code":"data(portfolio_allocations)"},{"path":"/reference/portfolio_allocations.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated Portfolio Allocation Data — portfolio_allocations","text":"data frame 500 observations 5 variables: portfolio_id Unique identifier risk_level Risk profile: Low, Medium, High equity_allocation Proportion allocated equities bond_allocation Proportion allocated bonds treatment Indicator allocation policy treatment return Observed return","code":""}]
